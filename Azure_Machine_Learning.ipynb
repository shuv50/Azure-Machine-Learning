{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Azure Machine Learning Day 1"
      ],
      "metadata": {
        "id": "VxVEp2qd3GPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "aERxaAd3CEm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade azureml-core\n",
        "!pip install azure-ai-ml\n",
        "!pip install azure-identity"
      ],
      "metadata": {
        "id": "8faOX2qHCGj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libaries"
      ],
      "metadata": {
        "id": "tTyq4Y743Pfs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n2A321x3FoP"
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient                          # Handle to the workspace\n",
        "from azure.identity import DefaultAzureCredential         # Authentication package\n",
        "from azure.identity import InteractiveBrowserCredential   # Authentication package\n",
        "from azure.ai.ml.entities import AmlCompute               # Compute\n",
        "from azure.ai.ml.entities import Environment              # Environment\n",
        "from azure.ai.ml.entities import Model                    # Model\n",
        "from azure.ai.ml import command                           # Job/command\n",
        "from azure.ai.ml import Input                             # Data input\n",
        "from azure.ai.ml.entities import ManagedOnlineEndpoint    # Manage endpoint \n",
        "from azure.ai.ml.entities import ManagedOnlineDeployment  # Manage endpoint\n",
        "import uuid                                               # Create UUID\n",
        "import os                                                 # System"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to workspace"
      ],
      "metadata": {
        "id": "tDG1PR9Q3V32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate\n",
        "credential = DefaultAzureCredential()                     # default credential\n",
        "# credential = InteractiveBrowserCredential()             # browser input credential\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"<subscription-id>\",\n",
        "    resource_group_name=\"<resource-group>\",\n",
        "    workspace_name=\"<workspace>\",\n",
        ")"
      ],
      "metadata": {
        "id": "juwgP2t9DROt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create compute cluster"
      ],
      "metadata": {
        "id": "3krtmhco3aX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute cluster name\n",
        "cpu_compute_target = \"cpu-cluster\"\n",
        "\n",
        "try:\n",
        "    # Check if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"Cluster {cpu_compute_target} already exists! Reusing it...\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    # Create the Azure ML compute object with the intended parameters\n",
        "    cpu_cluster = AmlCompute(\n",
        "        name = cpu_compute_target,    \n",
        "        type = \"amlcompute\",                  # Azure ML Compute is the on-demand VM service\n",
        "        size = \"STANDARD_DS3_V2\",             # VM Family\n",
        "        min_instances = 0,                    # Minimum running nodes when there is no job running\n",
        "        max_instances = 4,                    # Nodes in cluster\n",
        "        idle_time_before_scale_down = 180,    # How many seconds will the node running after the job termination\n",
        "        tier=\"Dedicated\",                     # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "    )\n",
        "    \n",
        "    print(f\"Creating new AzureML compute cluster {cpu_cluster.name} with compute size {cpu_cluster.size} ...\")\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)"
      ],
      "metadata": {
        "id": "Izq_acPY3ccr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create environment"
      ],
      "metadata": {
        "id": "Ke92vZ1G3dgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create environment file"
      ],
      "metadata": {
        "id": "SPDhs7Hbmev4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new directory for environment file\n",
        "dependencies_dir = \"./dependencies\"\n",
        "os.makedirs(dependencies_dir, exist_ok=True)\n",
        "\n",
        "# Create an environment file\n",
        "%%writefile {dependencies_dir}/conda.yml\n",
        "name: model-env\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8\n",
        "  - numpy=1.21.2\n",
        "  - pip=21.2.4\n",
        "  - scikit-learn=0.24.2\n",
        "  - scipy=1.7.1\n",
        "  - pandas>=1.1,<1.2\n",
        "  - pip:\n",
        "    - inference-schema[numpy-support]==1.3.0\n",
        "    - xlrd==2.0.1\n",
        "    - mlflow== 1.26.1\n",
        "    - azureml-mlflow==1.42.0\n",
        "    - psutil>=5.8,<5.9\n",
        "    - tqdm>=4.59,<4.60\n",
        "    - ipykernel~=6.0\n",
        "    - matplotlib"
      ],
      "metadata": {
        "id": "iFtBXzK13fLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and register environment"
      ],
      "metadata": {
        "id": "klqDS1B3miRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and register environment\n",
        "custom_env_name = \"aml-scikit-learn\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment\",\n",
        "    tags={\"scikit-learn\": \"0.24.2\"},\n",
        "    conda_file=os.path.join(dependencies_dir, \"conda.yml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\",\n",
        ")\n",
        "\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "print(f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\")"
      ],
      "metadata": {
        "id": "3LnvSZKKXgEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create training script"
      ],
      "metadata": {
        "id": "wmfj66RuXQ_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new directory for training script\n",
        "train_src_dir = \"./src\"\n",
        "os.makedirs(train_src_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "76CS2bMZXQsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {train_src_dir}/main.py"
      ],
      "metadata": {
        "id": "6TVsrIJ-YV2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
        "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
        "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
        "    args = parser.parse_args()\n",
        "   \n",
        "    # Start logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    # Enable autologging\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    # Read data\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "    print(\"input data:\", args.data)\n",
        "    df = pd.read_excel(args.data, header=1, index_col=0)\n",
        "\n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"num_samples\", df.shape[0])\n",
        "    mlflow.log_metric(\"num_features\", df.shape[1] - 1)\n",
        "\n",
        "    # Split data\n",
        "    train_df, test_df = train_test_split(df, test_size=args.test_train_ratio)\n",
        "\n",
        "    # Extracting the label column\n",
        "    y_train = train_df.pop(\"<column-name>\")\n",
        "\n",
        "    # Convert the dataframe values to array\n",
        "    X_train = train_df.values\n",
        "\n",
        "    # Extracting the label column\n",
        "    y_test = test_df.pop(\"<column-name>\")\n",
        "\n",
        "    # Convert the dataframe values to array\n",
        "    X_test = test_df.values\n",
        "\n",
        "    # Train model\n",
        "    print(f\"Training with data of shape {X_train.shape}\")\n",
        "    clf = GradientBoostingClassifier(\n",
        "        n_estimators=args.n_estimators, learning_rate=args.learning_rate\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Predict results\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Classification report\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Registering the model to the workspace\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=clf,\n",
        "        registered_model_name=args.registered_model_name,\n",
        "        artifact_path=args.registered_model_name,\n",
        "    )\n",
        "\n",
        "    # Saving the model to a file\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=clf,\n",
        "        path=os.path.join(args.registered_model_name, \"trained_model\"),\n",
        "    )\n",
        "    \n",
        "    # Stop Logging\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "5TEg9TrCYRth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure job/ command"
      ],
      "metadata": {
        "id": "HyOLYipiX803"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Job configuration\n",
        "registered_model_name = \"<model-name>\"\n",
        "\n",
        "job = command(\n",
        "    inputs=dict(\n",
        "        data=Input(\n",
        "            type=\"uri_file\",\n",
        "            path=\"<file-path>\",\n",
        "        ),\n",
        "        test_train_ratio=0.2,\n",
        "        learning_rate=0.25,\n",
        "        registered_model_name=registered_model_name,\n",
        "    ),\n",
        "    code=\"./src/\",  # location of source code\n",
        "    command=\"python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}\",\n",
        "    environment=\"aml-scikit-learn@latest\",\n",
        "    compute=\"cpu-cluster\",\n",
        "    experiment_name=\"<experiment-name>\",\n",
        "    display_name=\"<display-name>\"\n",
        ")"
      ],
      "metadata": {
        "id": "ndBILNCTX8ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submit the job"
      ],
      "metadata": {
        "id": "47EbgFA7Z_Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit job\n",
        "ml_client.create_or_update(job)"
      ],
      "metadata": {
        "id": "6qjrLLSDaBNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outputs and results"
      ],
      "metadata": {
        "id": "SRSULzj3aRHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fgdbRWjVaMkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a new online endpoint"
      ],
      "metadata": {
        "id": "cs2FIvltaiTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a unique name for the endpoint\n",
        "online_endpoint_name = \"<name>-endpoint-\" + str(uuid.uuid4())[:8]\n",
        "\n",
        "# Create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"this is an online endpoint\",\n",
        "    auth_mode=\"key\",\n",
        "    tags={\n",
        "        \"key_1\": \"value_1\",\n",
        "        \"key_2\": \"value_2\",\n",
        "    },\n",
        ")\n",
        "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "\n",
        "# Check endpoint status\n",
        "print(f\"Endpoint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")\n",
        "\n",
        "# Retrieve endpoint\n",
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "print(f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved')"
      ],
      "metadata": {
        "id": "Yg-29dMDajS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy the model to the endpoint"
      ],
      "metadata": {
        "id": "RpBBQcX3bD8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Take the latest model"
      ],
      "metadata": {
        "id": "LPi3ncZ4oCXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get latest model version\n",
        "latest_model_version = max(\n",
        "    [int(m.version) for m in ml_client.models.list(name=registered_model_name)]\n",
        ")\n",
        "\n",
        "# Latest model to deploy\n",
        "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)"
      ],
      "metadata": {
        "id": "ilIXKEJnoGRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an online deployment"
      ],
      "metadata": {
        "id": "mkZOMWXeoNrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an online deployment.\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    instance_type=\"Standard_DS3_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "blue_deployment = ml_client.begin_create_or_update(blue_deployment).result()"
      ],
      "metadata": {
        "id": "IvevlP79bF1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model"
      ],
      "metadata": {
        "id": "x-bUEZgQbMxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create test data file"
      ],
      "metadata": {
        "id": "RykymR1lseXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new directory for deployment\n",
        "deploy_dir = \"./deploy\"\n",
        "os.makedirs(deploy_dir, exist_ok=True)\n",
        "\n",
        "# Create the sample request json\n",
        "%%writefile {deploy_dir}/sample-request.json\n",
        "{\n",
        "  \"input_data\": {\n",
        "    \"columns\": [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22],\n",
        "    \"index\": [0, 1],\n",
        "    \"data\": [\n",
        "            [20000,2,2,1,24,2,2,-1,-1,-2,-2,3913,3102,689,0,0,0,0,689,0,0,0,0],\n",
        "            [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8]\n",
        "        ]\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "Pf9vTh3hbUCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the blue deployment"
      ],
      "metadata": {
        "id": "WHgr2x7isuGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the blue deployment with some sample data\n",
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    request_file=\"./deploy/sample-request.json\",\n",
        "    deployment_name=\"blue\",\n",
        ")"
      ],
      "metadata": {
        "id": "V9dmYEWpbWdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean up resources"
      ],
      "metadata": {
        "id": "3oMi6TjPbafc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the endpoint\n",
        "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
      ],
      "metadata": {
        "id": "OtG3ONGybeqF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}